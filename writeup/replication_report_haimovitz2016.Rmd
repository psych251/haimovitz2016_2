---
title: "Replication of Experiment 4 in ''What Predicts Children's Fixed and Growth Intelligence Mindsets? Not Their Parents' View of Intelligence but Their Parents' View of Failure'' by Haimovitz and Dweck (2016, *Psychological Science*)"
author: "Megumi Takada (metakada@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

## Introduction

### Overview of Original Study
Through a series of four experiments, Haimovitz and Dweck (2016) found that parents' views of failure predicted their children's views of intelligence; that is, parents who viewed failure as debilitating (rather than enhancing) were more likely to have children who believed that their intelligence is fixed (rather than malleable). Furthermore, parents' views of failure impacted the way that parents viewed their own children's failure; parents who believed that failure is debilitating focused on their children's performance and ability, instead of their learning. This study suggested that parents' views of failure are displayed to children in tangible ways through specific parenting practices (e.g., being concerned about their children's performance when they fail), which then impact children's own views of intelligence.

### Project Goals and Procedures
This project aimed to replicate the results reported in Experiment 4, which found a causal relationship between parents' views of failure and their response to a hypothetical scenario in which their child came home with a failing grade. Just like the original study, this replication study was also conducted online. Parents' views of failure, as well as other information, was collected using an online Qualtrics survey. A biased, 5-item survey was included to manipulate participants' views of failure, followed by an open-ended question that asked participants how they would react to the hypothetical scenario. Participants were parents with children of all ages, and they were recruited through an online recruitment platform called Prolific.

### Anticipated Challenges
Some parts of the methods outlined in the original paper were open to interpretation, and I relied on being able to reach out to the authors for some clarification. I also anticipated having to spend extra time figuring out how to randomly assign participants to one of two conditions in Qualtrics. Furthermore, the open-ended responses were coded by two raters in the original study, so I considered seeking an undergraduate RA or another PYSCH 251 student to help me code these responses. Finally, I anticipated needing extra time to carefully and reliably code the open-ended responses. 

### Project Justification
This project aligned with my broader interests in reading mindset interventions. I'm particularly interested in the role that parents and teachers play in fostering children's mindset and reading development. I thought parents would be especially interesting to study at this time, given that children were more likely to be spending time at home with their parents during the COVID-19 pandemic. In a recent independent project, I found that parents' views of failure were related to their children's reading abilities. This project will allow me to start thinking more deeply about *how* these parental views could possibly cause children to think and perform in a certain way.

### Links

* The original paper by Haimovitz and Dweck (2016) can be accessed through https://github.com/psych251/haimovitz2016_2/blob/main/original_paper/haimovitz2016_paper.pdf
* The Github repository for this project can be accessed through https://github.com/psych251/haimovitz2016_2

## Methods

### Power Analysis

**Original effect size of the main analyses:** ηp2 = .075 (d = 0.5695)

**Power analysis to detect this effect size with an alpha of 0.05:**

 * To achieve 80% power, 100 parents are required.
 * To achieve 90% power, 132 parents are required.
 * To achieve 95% power, 164 parents are required.
 
Given the class budget and feasibility in coding all the responses within the duration of the quarter-long class, this replication project aimed to achieve 80% power.

### Planned Sample
120 parents (60 mothers and 60 fathers) were recruited to achieve 80% power and to account for participants whose data may not be usable. Parents were recruited through a crowdsourcing platform called Prolific. The participant pool on Prolific was filtered by parental status to specifically reach parents.

In the original study, 310 adults from a crowdsourcing platform called Amazon Mechanical Turk completed an initial survey asking whether they were a parent. Out of these adults, 132 of them reported to be a parent and were chosen to participate in the study. The sample also had the following demographics: 

* "57% female" 
* "31% had a high school diploma or some college education, 51% had a college degree, and 18% had a postgraduate degree." 
* "75% White, 12% African American, 7% Asian American, and 6% Hispanic"

### Materials and Procedure

#### General Materials and Procedures
The replication study followed the materials and procedures outlined in the original article: 

>"Participants completed an online survey initially assessing several beliefs, including their perceptions of their child’s competence (assessed with same measure as in Study 1; α = .79). Then we temporarily manipulated failure mind-sets by randomly assigning the parents to complete one of two five-item biased questionnaires, written to foster agreement with either a failure-is-debilitating mind-set (e.g., “Experiencing failure can lead to negative feelings, like shame or sadness, that interfere with learning”) or a failure-is-enhancing mind-set (e.g., “Experiencing failure can improve performance in the long run if you learn from it”). All measures used a 6-point rating scale from 1 (strongly disagree) to 6 (strongly agree). ...

>We then asked participants to read and vividly imagine a scenario in which their child came home from school with a failing grade on a math quiz, as in Study 2. They then wrote what they would do, think, and feel in response. Finally, participants reported on their failure mind-sets (α = .82), using the same items as in Study 1, as part of a survey that included a few other items."

All survey items outlined in the supplementary ["Materials and Measures" document](https://github.com/psych251/haimovitz2016_2/blob/main/original_paper/haimovitz2016_materials_measures.pdf) were used. 

From reading the original article and supplementary document, it was not clear whether the middle points on the Likert scale were labelled. Based on similar studies examining intelligence mindsets, I decided to label the middle points with "mostly dis/agree" and "slightly dis/agree." It was also unclear what "other items" were included in the final survey asking participants to report on their failure mindsets. These "other items" were not needed to replicate the main results, so they were omitted from this replication study. As I was also not sure where to collect demographic data (i.e., sex, race, education level, child's age), I decided to collect this information as part of the final survey at the very end of the study.

Furthermore, I decided to include a funnel debrief at the end to assess whether the effects I observed were due to priming rather than parents' prior knowledge of mindset research. These questions were not a part of the original study. 

Here is a link to the survey that was used to conduct the replication study: 
https://stanforduniversity.qualtrics.com/jfe/form/SV_9yLXExjnUOE8XzM

#### Data Processing/Coding
The following procedures from the original article outlined how the open-ended responses were coded. These procedures, in addition to guidelines outlined in the supplementary ["Materials and Measures" document](https://github.com/psych251/haimovitz2016_2/blob/main/original_paper/haimovitz2016_materials_measures.pdf) were carefully followed except for a few exceptions explained below. 

> "Two raters, blind to condition, coded the open-ended responses. The first author developed a coding scheme on the basis of an initial reading of the responses and then made clarifying revisions on the basis of feedback from the two raters.

> The codes were broken down into two main categories of interest: performance-oriented responses and learning-oriented responses. Coders gave a score of 1 each time a code was present. Codes in the performance-oriented category were responses that focused on judgments of ability, particularly as a stable trait (e.g., “I would think maybe my child is just not that good at math”); comfort for lack of ability (e.g., “It’s ok that you got an F. You tried your best”); contingent self-worth based on their child’s performance (e.g., “I’d feel bad about myself”); pity for their child’s lack of ability (“I would feel a little nervous for my child because I know how hard it can be”); grades as a goal (e.g., “I would . . . hope their grades from previous [tests] are high enough to make up for the test”); and social comparison (“I would also want to know how the other children in the class scored”). Codes in the learning-oriented category were responses that focused on judgments of effort (e.g., “I would tell my son he needs to study harder”); strategies, which included both general strategies (e.g., “he didn’t study the material in the right way”) and specific study or test-taking strategies (e.g., “I would also say that double checking your work before you hand it in is a good habit to get into”); help seeking (e.g., “I would get her a math tutor”); mastery, or conceptual understanding, as a goal (e.g., “the important thing we need to do is try to understand the concepts behind the problems he got wrong, and then study those”); interest (e.g., “I would hope that the results of the test would not stop her from enjoying the class and wonder about ways I could help keep her liking of the subject going”); and explicit characterizations of failure as enhancing, or good (e.g., “It is ok to make mistakes and fail sometimes, because that’s how people learn”).

> Two statements that repeated the same sentiment were not coded as two instances (e.g., “I would question how much studying did they do” and “I would also ask . . . do they think they studied enough” would be one code for effort). However, two statements that expressed different ideas but fell under the same code were marked as two instances (e.g., “I would question my child to make sure that she studied the correct material thoroughly” and “I would ask to make sure that she was paying attention in class” would be marked as two codes for strategies, as these statements represent different strategies). If a statement fell under two codes and one was more specific than the other, only the more specific classification was counted. That is, although effort and help seeking can be different types of strategies, statements expressing these ideas were coded only as effort and help seeking, not also as strategies.

> Scores for performance-oriented and learning-oriented responses were each created by summing all instances of their respective subcategories. Two coders rated 20 responses (15%) to assess reliability."

As there was already a coding scheme developed by the original authors, I did not create my own coding scheme. Rather, I carefully reviewed the coding scheme outlined in the supplementary document to code the responses. I considered recruiting an undergraduate RA or another PSYCH 251 student to serve as the second rater, but in the end, I decided to code all of the responses on my own. I came to this decision during the pilot study, when I noticed it takes a while to get used to the coding scheme outlined by the authors. Given that the project needed to be completed in a quarter, it didn't seem feasible to recruit another student and have them reliably code the responses in this short time frame. By scrambling the responses before downloading and viewing the open-ended responses for coding, I was able to ensure that I remained blind to condition.

### Confirmatory Analysis Plan

#### Data Exclusion
The original paper did not mention whether participants were excluded, but in this replication study, I planned to exclude data from participants if the open-ended responses were not possible to code (e.g., unintelligible responses, responses such as "I don't know.").

#### Key Analysis of Interest

**The key analysis of interest will be an unpaired, two-tailed t test comparing performance-oriented responses between the two conditions. The analysis will aim to replicate the following result:**

>"Parents who were induced to hold a failure-is-debilitating mind-set were more likely to react with concerns about their child’s performance and lack of ability, t(131) = 3.246, p < .001, ηp2 = .075 ... compared with those who were induced to hold a failure-is-enhancing mind-set."

This finding was chosen as the main analysis of interest, as the purpose of Experiment 4 was to examine whether there was a causal effect of parents' failure mindset on their reaction to a scenario in which their child hypothetically came home with a failing grade. In the original study, two t tests were conducted to compare both performance-oriented responses and learning-oriented responses between the two conditions. The difference observed in performance-oriented responses had a larger effect size and was therefore chosen as the main, confirmatory analysis of interest. As an exploratory analysis, I aimed to replicate the difference observed in learning-oriented responses (i.e., "Parents who were induced to hold a failure-is-debilitating mind-set were ... less likely to react with support for their child’s learning and mastery, t(131) = −2.04, p = .043, ηp2 = .031, compared with those who were induced to hold a failure-is-enhancing mind-set (see Fig. 2)."

### Exploratory Analysis Plan

#### Demographics
I explored the demographics of the replication sample, mainly child's age, parents' socioeconomic status (education level), parents' gender, and parents' race/ethnicity. 

#### Covariates
The effects of child's age were tested on key variables, namely parents' scores on performance-oriented responses and learning-oriented responses.

#### Manipulation Check
One-sample t tests were used to compare "the mean in each priming condition with the scale's midpoint (3.5)." Furthermore, another t test was conducted to confirm that the "biased-questionnaire manipulation effectively changed parents’ self-reported failure mind-sets at the end of the survey."

Composite scores for failure mindsets and the biased questionnaires were created in the same way as the original paper: 

* **Failure Mindset Survey:** "We created a composite variable by reverse-scoring items that represented a failure-is-enhancing mind-set and then averaging responses to all the items; thus, higher numbers indicated a more debilitating view of failure."
* **Biased Questionnaires**: "The responses were averaged to form a composite score, such that higher scores on the failure-is-debilitating biased questionnaire reflected a more debilitating view of failure and higher scores on the failure-is-enhancing biased questionnaire reflected a more enhancing view of failure."

#### Secondary Analysis of Interest: Learning-Oriented Responses
The key analysis of interest (confirmatory analysis) compared performance-oriented responses between the two conditions. This secondary analysis of interest compared the learning-oriented responses using the same, unpaired, two-tailed t test. 

#### Funnel Debrief
Apart from any of the analyses reported in the original study, I also explored whether parents' knowledge of mindset research was associated with their learning-oriented and performance-oriented responses.

### Differences from Original Study
I attempted as faithful a replication as possible, but there were some differences between the current replication study and the original study. 

* **Crowdsourcing Platform**: The original study was conducted on Amazon Mechanical Turk, but the current project used Prolific. Both Amazon Mechanical Turk and Prolific are crowdsourcing platforms, so the study procedures were fairly similar. Prolific seems to provide higher data quality, so the results in this replication project may show higher internal consistency for survey measures and better overall data quality.

* **Procedures**: Some parts of the procedures in the original article were unclear, specifically the labels of the middle points on the Likert scale, as well as the items in the final survey. It is common to have "mostly dis/agree" and "slightly dis/agree" as labels in such surveys, so this potential difference should not compromise the results. Adding demographic questions at the very end of the final survey should not change the claims in the original article as well. Even if the demographic questions altered parents' thoughts, it was possible to avoid having these questions affect the results by including the questions at the very end of the study and disabling going back to previous questions. Furthermore, a funnel debrief was added at the end to rule out the possibility that prior knowledge of mindset research was driving observed effects. Finally, only one rater coded the responses, rather than two raters. 

* **Coding Scheme**: In the original study, the coding scheme was developed by reading through the open-ended responses and developing a coding scheme based on those responses. In this project, a new coding scheme was not made; rather, the original coding scheme was adopted. Creating a new coding scheme based on the responses collected in this replication study may have fundamentally changed the open-ended response measure. As the original study included a fairly large sample size and was likely to have represented a variety of responses, I anticipated that the coding scheme created by the authors would work well for this replication study as well.

Overall, the differences between the original study and replication study did not seem to be significant enough to cause differences in the results. I was able to contact the first author and confirm that my version of the survey was similar to that of the original study.

<!-- ### Methods Addendum (Post Data Collection) -->

<!-- You can comment this section out prior to final report with data collection. -->

<!-- #### Actual Sample -->
<!--   Sample size, demographics, data exclusions based on rules spelled out in analysis plan -->

<!-- #### Differences from pre-data collection methods plan -->
<!--   Any differences from what was described as the original plan, or “none”. -->


## Results

### Data preparation

```{r message=FALSE}
# Data Preparation

## Clean Workspace
rm(list=ls())

## Load Relevant Libraries and Functions
library(rmarkdown)
library(tidyverse)
library(knitr)
library(qualtRics)
library(psych)      # for reverse coding
library(ggsignif)   # to add significance bars

## Load Pilot Data

### authenticate API
#qualtrics_api_credentials(api_key = "XXX", base_url="stanforduniversity.ca1.qualtrics.com", install = TRUE)

### get Qualtrics survey data
qualtrics_data <- fetch_survey(surveyID = "SV_9yLXExjnUOE8XzM", force_request = TRUE)

### filter out all pilot participants (commented out for now but will include once I run study)
#qualtrics_data <- qualtrics_data |>
#  filter(StartDate >= as.Date("2021-11-18"))

### create a new file to scramble open-ended responses to blind myself to condition before coding
data_response_scrambled <- qualtrics_data |>
  select("prolific_id", "oer_1", "oer_2", "oer_3") |>
  arrange(prolific_id)

## save both csv files

### scrambled, open-ended responses
write.csv(data_response_scrambled, "../raw_data/data_response_scrambled.csv")

### rest of the Qualtrics data, WITHOUT the open-ended responses
qualtrics_data <- qualtrics_data |>
  select(-c("oer_1", "oer_2", "oer_3"))
write.csv(qualtrics_data, "../raw_data/qualtrics_data.csv")
```

```{r message=FALSE}
## load coded responses
coded_response <- read.csv("../coded_data/data_response_scrambled_coded.csv", header = TRUE, sep = ",")

## data exclusion / filtering: filter out all participants whose open-ended response scores was NA
coded_response <- coded_response |>
  filter(!is.na(coded_por) | !is.na(coded_lor))

## prepare Qualtrics data (take out irrelvant variables and label each participant with condition)
qualtrics_data <- qualtrics_data |>
  #take out variables that contain DO
  select(-contains("DO")) |>
  #label each participant with the correct condition
  mutate(condition = ifelse(!is.na(fid_manip_1), "debilitating", 
                            ifelse(!is.na(fie_manip_1), "enhancing", NA)))

## merge data 
metadata <- merge(qualtrics_data, coded_response, by = "prolific_id")
```

### Confirmatory analysis

**Main Analysis of Interest:** Were parents who hold a failure-is-debilitating mind-set more likely to react with concerns about their child’s performance and lack of ability?

#### Original Study Result 

> “Parents who were induced to hold a failure-is-debilitating mind-set were more likely to react with concerns about their child’s performance and lack of ability, t(131) = 3.246, p < .001, ηp2 = .075 … compared with those who were induced to hold a failure-is-enhancing mind-set.”

#### Unpaired, Two-Tailed T-Test

```{r}
# Make a dataframe for the FID and FIE conditions to conduct t-test
data_coded_response_fie <- metadata |>
  filter(condition == "enhancing")
data_coded_response_fid <- metadata |>
  filter(condition == "debilitating")

# T-Test 
t_test_por <- t.test(data_coded_response_fie$coded_por, data_coded_response_fid$coded_por, alternative = "two.sided", var.equal = FALSE)

t_test_por
```

#### Figure Comparison

##### Replication Project Figure

```{r}
# compute relevant information to generate figure   
data_coded_response_por_fig <- metadata |>
  group_by(condition) |>
  summarise(
    count = n(),
    mean_por = mean(coded_por, na.rm = TRUE),
    sd_por = sd(coded_por, na.rm = TRUE), 
    sem_por = sd_por / sqrt(count)
  )

head(data_coded_response_por_fig)

# generate figure
fig_condition_por <- ggplot(data_coded_response_por_fig, aes(x=condition, y=mean_por)) +
  geom_bar(position="dodge", stat="identity") + 
  geom_errorbar(aes(ymin=mean_por-sem_por,
                    ymax=mean_por+sem_por),
                width=0.1,
                position=position_dodge(0.9)) +
  geom_jitter(data=metadata, aes(x=condition, y=coded_por), width = 0.1, height = 0) +
  ylab("Number of Performance-Oriented Responses") +
  scale_x_discrete("Condition",
                   labels=c("debilitating" = "Failure-is-Debilitating Condition", 
                            "enhancing" = "Failure-is-Enhancing Condition")) +
  geom_signif(
    y_position = c(1.75), 
    xmin = c(1.1), xmax = c(1.9),
    annotation = c(paste("p=", round(t_test_por$p.value, digits = 3))), tip_length = 0.0,
    textsize = 3.5) + 
  theme_classic()

fig_condition_por
```

##### Original Figure

The main analysis of interest compared the performance-oriented responses shown on the left side of this figure.

![Fig 2 from Haimovitz & Dweck (2016).](../original_paper/haimovitz2016_fig2.png)

### Exploratory analyses

#### Demographics of Prolific Sample

##### Child's Age
```{r}
kable(table(metadata$dem_childage), col.names = c("Child's Age", "N"))
```

##### Parental Education
```{r}
kable(table(metadata$dem_education), col.names = c("Education Level", "N"))
```

##### Parents' Gender

Each participant may have chosen more than one category. 

```{r}
data_gender <- metadata |>
  select(dem_gender_1:dem_gender_8) |>
  pivot_longer(dem_gender_1:dem_gender_8, 
               names_to = "qualtrics_category",
               values_to = "gender") |>
  filter(!is.na(gender)) |> 
  mutate(count = 1) |> 
  group_by(gender) |>
  summarise(N = sum(count)) |>
  kable(col.names = c("Gender", "N"))
data_gender
```

##### Parents' Race and Ethnicity

Each participant may have chosen more than one category. 

```{r}
data_race_ethnicity <- metadata |>
  select(dem_raceethnicity_1:dem_raceethnicity_8) |>
  pivot_longer(dem_raceethnicity_1:dem_raceethnicity_8, 
               names_to = "qualtrics_category",
               values_to = "race_ethnicity") |>
  filter(!is.na(race_ethnicity)) |> 
  mutate(count = 1) |> 
  group_by(race_ethnicity) |>
  summarise(N = sum(count)) |>
  kable(col.names = c("Race/Ethnicity", "N"))
data_race_ethnicity
```

#### Covariates: Child's Age

##### Is child's age associated with parents' performance-oriented responses? 
```{r}
summary(lm(metadata$dem_childage ~ metadata$coded_por))
```

##### Is child's age associated with parents' learning-oriented responses? 
```{r}
summary(lm(metadata$dem_childage ~ metadata$coded_lor))
```

##### Figure 
```{r fig.width=7, fig.height = 4} 
data_age_covariate <- metadata |>
  pivot_longer(coded_por:coded_lor,
               names_to = "code_type", 
               values_to = "response")

fig_age_covariate <- ggplot(data = data_age_covariate, aes(x = dem_childage, y = response)) +
  facet_wrap(~code_type, 
             labeller = labeller(code_type = c("coded_lor" = "Learning-Oriented Responses",
                                               "coded_por" = "Performance-Oriented Responses"))) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlab("Child's Age") +
  ylab("Number of Responses") +
  scale_x_continuous(breaks=seq(0,20,1)) +
  theme_bw()
fig_age_covariate
```

#### Manipulation Check Part 1: Was the parents' agreement with each of the intended mindsets above the midpoint?

##### Original Study Result

> “One-sample t tests comparing the mean in each priming condition with the scale’s midpoint (3.5) showed that participants’ agreement with the intended mind-set was above the midpoint in both the failure-is-debilitating condition (M = 4.41, SD  = 1.07), t(56) = 6.45, p < .001, and the failure-is-enhancing condition (M = 5.14, SD = 0.829), t(74) = 17.11, p < .001.”

```{r}
# Prepare Data

## create dataframe with names of measures and reverse scores
data_long <- metadata |>
  #format into tidy data
  pivot_longer(competence_1:failure_6, #1st item in competence survey to last item in failure survey 
               names_to = "item", 
               values_to = "value") |>
  #reverse score 
  mutate(#add survey name
         measure = ifelse(str_detect(item, "competence_")==TRUE, "competence",
                          ifelse(str_detect(item, "fid_manip_")==TRUE, "biased_fid",
                                 ifelse(str_detect(item, "fie_manip_")==TRUE, "biased_fie",
                                        ifelse(str_detect(item, "failure_")==TRUE, "failure", 
                                               ifelse(str_detect(item, "intelligence_")==TRUE, "intelligence", NA))))),
         #name the variables that need to be reverse coded
         reverse_score = ifelse(item == "failure_1" | item == "failure_2" | item == "failure_3" | item == "intelligence_3" | item == "intelligence_4", TRUE, FALSE),
         #add "value with reverse score" (if the variable was flagged to reverse score above, then reverse code, if not, then keep original rating)
         value_w_rs = ifelse(reverse_score == TRUE, (reverse.code(-1, value, mini = 1, maxi = 6)), value))
```

```{r}
# Compare mean in each priming condition with midpoint

## get relevant manipulation survey data and compute composite
data_manip_1 <- data_long |>
  filter(measure == "biased_fid" | measure == "biased_fie") |>
  filter(!is.na(value_w_rs)) |> 
  group_by(prolific_id, measure) |>
  summarise(composite = mean(value_w_rs))

head(data_manip_1)

## compute mean 
data_manip_1_fig <- data_manip_1 |>
  group_by(measure) |>
  summarise(mean = mean(composite, na.rm = TRUE),
            count = n(),
            sd = sd(composite, na.rm = TRUE),
            sem = sd / sqrt(count))

head(data_manip_1_fig)
```

##### Was the intended mind-set above the midpoint in the failure-is-debilitating condition?

```{r}
# make a dataframe for the FID manipulation survey
data_manip_1_fid <- data_manip_1 |> 
  filter(measure == "biased_fid")

# Was the parents' agreement with each of the intended mindsets above the midpoint?
t.test(data_manip_1_fid$composite, mu = 3.5, alternative = "two.sided")
```

##### Was the intended mind-set above the midpoint in the failure-is-enhancing condition?

```{r}
# make a dataframe for the FIE manipulation survey
data_manip_1_fie <- data_manip_1 |>
  filter(measure == "biased_fie")

# Was the parents' agreement with each of the intended mindsets above the midpoint?
t.test(data_manip_1_fie$composite, mu = 3.5, alternative = "two.sided")
```

##### Figure

```{r}
# generate figure for failure-is-debilitating and failure-is-enhancing survey
fig_manip_1 <- ggplot(data_manip_1_fig, aes(x=measure, y=mean)) +
  geom_bar(position="dodge", stat="identity", width=0.75) + 
  geom_errorbar(aes(ymin=mean-sem,
                    ymax=mean+sem),
                width=0.1,
                position=position_dodge(0.9)) +
  geom_jitter(data=data_manip_1, 
              aes(x=measure, y=composite),
              width = 0.1, height = 0) +
  scale_x_discrete("Condition",
                   labels=c("biased_fid" = "Failure-is-Debilitating",
                            "biased_fie" = "Failure-is-Enhancing")) +
  expand_limits(y=c(0,7)) +
  scale_y_continuous(breaks=seq(0,7,1)) +
  ylab("Composite Score of Biased Survey") +
  geom_hline(yintercept=3.5, linetype="dashed") + 
  annotate(geom="text", x=2.48, y=3.7, label="Midpoint") +
  theme_classic()

fig_manip_1
```

#### Manipulation Check Part 2 (Main Manipulation Check): Did the parents in the failure-is-debilitating condition report more of a failure-is-debilitating mindset than the parents in the failure-is-enhancing condition?

##### Original Study Result

>  "Indeed, the manipulation seemed to shift parents’ mind-sets, t(124) = 2.53, p = 0.013: Parents in the failure-is-enhancing condition reported more of a failure-is-enhancing mind-set than did parents in the failure-is-debilitating condition."

```{r}
# get relevant manipulation survey data and compute composite
data_manip_2 <- data_long |>
  filter(measure == "failure") |>
  filter(!is.na(value_w_rs)) |>
  group_by(prolific_id, condition) |>
  summarise(composite_f = mean(value_w_rs))

head(data_manip_2)
```

##### T-Test

```{r}
# make a dataframe for the FID and FIE conditions
data_manip_2_fid <- data_manip_2 |>
  filter(condition == "debilitating")
data_manip_2_fie <- data_manip_2 |>
  filter(condition == "enhancing")

# T-Test
data_manip_2_ttest <- t.test(data_manip_2_fid$composite_f, data_manip_2_fie$composite_f, alternative = "two.sided", var.equal = FALSE)
data_manip_2_ttest 
```

##### Figure

```{r}
# compute relevant information to generate figure        
data_manip_2_fig <- data_manip_2 |>
  group_by(condition) |>
  summarise(
    count = n(),
    mean_f = mean(composite_f, na.rm = TRUE),
    sd_f = sd(composite_f, na.rm = TRUE), 
    sem_f = sd_f / sqrt(count)
  )

head(data_manip_2_fig)

# generate figure 
fig_manip_2 <- ggplot(data_manip_2_fig, aes(x=condition, y=mean_f)) +
  geom_bar(position="dodge", stat="identity") + 
  geom_errorbar(aes(ymin=mean_f-sem_f,
                    ymax=mean_f+sem_f),
                width=0.1,
                position=position_dodge(0.9)) +
  geom_jitter(data=data_manip_2, 
              aes(x=condition, y=composite_f), 
              width = 0.1, height = 0) +
  scale_x_discrete("Condition",
                   labels=c("debilitating" = "Failure-is-Debilitating Condition", 
                            "enhancing" = "Failure-is-Enhancing Condition")) +
  ylab("Failure Mindset (Failure-Is-Debilitating)") +
  expand_limits(y=c(0,7)) +
  scale_y_continuous(breaks=seq(0,7,1)) +
  geom_signif(
    y_position = c(6), 
    xmin = c(1.1), xmax = c(1.9),
    annotation = c(paste("p=", round(data_manip_2_ttest$p.value, digits = 3))), tip_length = 0.0,
    textsize = 3.5
  ) +
  theme_classic()

fig_manip_2
```

#### Secondary Analysis of Interest: Learning-Oriented Responses

Were parents who hold a failure-is-debilitating mind-set less likely to react with support for their child’s learning and mastery?

##### Original Study Result 

> "Parents who were induced to hold a failure-is-debilitating mind-set were ... less likely to react with support for their child’s learning and mastery, t(131) = −2.04, p = .043, ηp2 = .031, compared with those who were induced to hold a failure-is-enhancing mind-set (see Fig. 2)."

##### Unpaired, Two-Tailed T-Test

```{r}
# Are the number of learning-oriented responses different for the two groups?
t_test_lor <- t.test(data_coded_response_fie$coded_lor, data_coded_response_fid$coded_lor, alternative = "two.sided", var.equal = FALSE)
t_test_lor
```

##### Replication Study Figure

```{r}
# compute relevant information to generate figure   
data_coded_response_lor_fig <- metadata |>
  group_by(condition) |>
  summarise(
    count = n(),
    mean_lor = mean(coded_lor, na.rm = TRUE),
    sd_lor = sd(coded_lor, na.rm = TRUE), 
    sem_lor = sd_lor / sqrt(count)
  )

# generate figure
fig_condition_lor <- ggplot(data_coded_response_lor_fig, aes(x=condition, y=mean_lor)) +
  geom_bar(position="dodge", stat="identity") + 
  geom_errorbar(aes(ymin=mean_lor-sem_lor,
                    ymax=mean_lor+sem_lor),
                width=0.1,
                position=position_dodge(0.9)) +
  geom_jitter(data=metadata, aes(x=condition, y=coded_lor), width = 0.1, height = 0) +
  ylab("Number of Learning-Oriented Responses") +
  scale_x_discrete("Condition",
                   labels=c("debilitating" = "Failure-is-Debilitating Condition", 
                            "enhancing" = "Failure-is-Enhancing Condition")) +
  geom_signif(
    y_position = c(3.5), 
    xmin = c(1.1), xmax = c(1.9),
    annotation = c(paste("p=", round(t_test_lor$p.value, digits = 3))), tip_length = 0.0,
    textsize = 3.5) + 
  theme_classic()

fig_condition_lor
```

##### Side-By-Side Comparison with Fig 2 in Haimovitz & Dweck (2016)

```{r}
# Create figure of two pairs of bar graphs that parallels Fig 2 in the original paper

## compute relevant information to generate figure
data_coded_response_combined_fig <- metadata |>
  pivot_longer(coded_por:coded_lor,
               names_to = "response_type",
               values_to = "num_response") |>
  group_by(condition, response_type) |>
  summarise(count = n(),
            mean = mean(num_response, na.rm = TRUE),
            sd = sd(num_response, na.rm = TRUE), 
            sem = sd / sqrt(count),)
head(data_coded_response_combined_fig)

## generate figure
fig_coded_response <- ggplot(data_coded_response_combined_fig, aes(x=response_type, y=mean, group=condition, fill=condition)) +
  geom_bar(position="dodge", stat="identity") + 
  geom_errorbar(aes(ymin=mean-sem,
                    ymax=mean+sem),
                width=0.1,
                position=position_dodge(0.9)) +
  scale_x_discrete("Parental Responses to Child-Failure Scenario",
                   limits=c("coded_por", "coded_lor"), #not working due to back-end bug
                   labels=c("coded_lor" = "Learning-Oriented", 
                            "coded_por" = "Performance-Oriented")) +
  ylab("Number of Responses") +
  annotate("text", x = 1:2, y = 3.5:3.5, 
           label = c(paste("p=", round(t_test_por$p.value, digits = 3)), 
                     paste("p=", round(t_test_lor$p.value, digits = 3)))) +
  geom_segment(aes(x = 0.8, y = 3.3, xend = 1.2, yend = 3.3)) +
  geom_segment(aes(x = 1.8, y = 3.3, xend = 2.2, yend = 3.3)) +
  theme_bw() +
  theme(legend.position="top", 
        legend.title = element_blank(),
        panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),  
        axis.line=element_line()) +
  scale_fill_brewer(labels=c("Failure-Is-Debilitating Condition",
                               "Failure-Is-Enhancing Condition"), 
                    palette = "Dark2")

fig_coded_response
```

![Fig 2 from Haimovitz & Dweck (2016).](../original_paper/haimovitz2016_fig2.png)


<!-- ## Discussion -->

<!-- ### Summary of Replication Attempt -->

<!-- Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.   -->

<!-- ### Commentary -->

<!-- Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long. -->
